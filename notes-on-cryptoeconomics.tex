\documentclass[12pt]{report}
\overfullrule=2cm

\usepackage{hyperref}

\newcommand{\link}[2]{\href{#1}{#2}}

\begin{document}

\title{Notes on cryptoeconomics}
\author{Oskar Thoren\thanks{Email: ot@oskarthoren.com}$^{,}$\thanks{Web: http://oskarth.com}}

\maketitle

\chapter{Prelude}

Notes on cryptoeconomics and related subjects. Started September 9, 2018.

With a focus towards specific problems that I want to solve. These problems
should have more precise problem statement. A rough outline will do for now.
These are specific problems that are meaningful and relevant and guide reading,
even if more general tools are desirable and there is other problems and stuff
that is useful.

Additionally, specific papers and free recall notes of these. Then we'll see
where a synthesis makes sense.

Also roughly answer things like: what do you know and what would be useful to
know?

Previously did a write-up of A Layman's Introduction to Cryptoeconomics.

\textbf{Questions}:

1) Incentivized Whisper nodes, including mail server. General problem: full node
incentivization and running without a cluster or servers at all.

See things like: Miners; rent proposal; full node incentivization, as well as
altruistic models (scale arguments, E.O. Wilson tangent?). Also worth checking
re BT and Tor nodes, etc. Any form of p2p.

Litmus test: A system survive without a cluster or subsidised servers.

2) DAO and compensation, funding of public goods and the likes.

Should probable be phrased as question. Finding a good question statement is
useful. See Polya for examples of ways of thinking structurally about these
problems.

Litmus test: organization/community survive without core contributors/paycheck.

3) More generally, how to balance decentralization/scalability/security? This is
essentially Ethereum 2.0 and grokking it at a fundamental level.

\chapter{Readings}

Anything by Vitalik or Szabo is a good start and meaty. Have a bunch in inbox.
Meta: what specific ways of reading is useful? Something like the following to
keep in mind:

- Who are the actors in this system?
- What's the set of rewards and punishments?
- What tools are used and introduced?
- Is there any empirical basis for this or is it still a theoretical construct?
- Lindy effect: Comparable that's 30y/10y or so old? Otherwise maybe BS.

\section{Vitalik - Minimal Slashing Conditions (2017)}
\link{https://medium.com/@VitalikButerin/minimal-slashing-conditions-20f0b500fc6c}{link}

Interest of this is around learning how to think about *slashing conditions*,
i.e. punishing bad behavior. Probably lacking some pre-requsites in *byzantine
fault tolerance consensus algorithms*.

What is the intention of using "economic finality" in Casper?
To make 51% attacks very expensive (~$70m) once block is finalized. Even if
majority of validators work together it means huge economic cost.

What does it mean for a block to be economically finalized?
\textbf{Definition}: a block is *economically finalized* with *cryptoeconomic
security margin* $X if it is guaranteed to be in the canonical chain for ever,
or if it costs set of actors at least $X to remove it from the state.

This is key to Casper design. Validators must submit a *security deposit* to
participate, and this can get taken away if the protocol isn't followed. Under
what conditions is what is referred to as *slashing conditions*.

Example: PREPARE and COMMIT statements. Key to byzantine fault tolerance
consensus two phase consensus design apparently, but not elaborated on right
now.

If a validator sends two PREPARE messages within same epoch but with different
hashes, say, that should be punished. It's easy for an honest validator not to
do this.

When is a block hash *finalized*?
When, within a given epoch, you get enough messages of type `[COMMIT, epoch,
  hash]` that the validator's deposits add up to 2/3 of the *active validator
set* deposits.

There are some conditions that slashing conditinos have to meet. One is around
*accountable safety*, which says something like: if two hashes gets committed (fork) then
at least 1/3 of validators can be penalized. Other is around *plausible liveness*, which
is something like: system shouldn't be stuck, there has to be a set of messages
that can be sent that 2/3 agree on without validating slashing conditions.

Let's be a bit more formal.

What conditions does *slashing conditions* need to satisfy? (sloppy)
Accountable safety and plausible liveness.

What does Vitalik mean by *accountable safety*?
If two conflicting hashes gets finalized, it must be (provably) true that at
least 1/3 of validators violated some slashing conditions. This is the
``economic finality'' idea.

What does Vitalik mean by *plausible liveness*?
Unless 1/3 of validators violate some slashing condition, there must be a set of
messages 2/3 of validators can send that finalize a new hash without violating
slashing conditions.

This reminds me of: Schelling points, as well as structured order for Anki (Q/A).

I assume this is directly taken from BFT literature regarding safety and
liveness. It'd be useful to understand these in more depth, along with things
like sync assumptions (sync/partial/async). It isn't clear to me how this is
directly related to any of the specific problems addressed in top, though it is
vital for Ethereum 2.0 in general.

There's examples of safety but not liveness, and v.v. Shows failure modes.

These are like little puzzles. Should be able to come up with answers myself.

Quoting algorithm 1:
> Algorithm 1: every validator has exactly one opportunity to send a message of
the form ["COMMIT", HASH]. If 2/3 of validators send a COMMIT for the same hash,
that hash is finalized. Sending two COMMIT messages violates a slashing
condition.

Is this safe and live? Safety: if we have two conflicting hashes...

Quoting algorithm 2:
> Algorithm 2: every validator has exactly one opportunity to send a message of
the form ["COMMIT", HASH, epoch]. If 2/3 of validators send a COMMIT for the
same hash with the same epoch number, that hash is finalized. Sending two COMMIT
messages with different hashes with the same epoch number violates a slashing
condition.

Is this safe and live?

Not enough time to do this properly. Worth re-visiting though.

The pudding is: you can get safety and liveness, but this is actually quite
hard. It requires four slashing conditions, and there's a formal proof by Yoichi
here: https://yoichihirai.com/minimal.pdf

These are, roughly: COMMIT REQ (sending commit requires 2/3 prepares), PREPARE
REQ (don't quite follow, but ancestor epoch related), PREPARE COMMIT CONSISTENCY
(if you make commit you saw prepares, so prepares should ref recent epoch), NO
DBL PREPARE (can't prepare twice in one epoch).

I'm curious where this split in PREPARE and COMMIT comes from, surely that's a
canonical BFT paper somewhere? Same re safety and liveness. What does distsys
MIT curriculum say? (can't find anything at first glance).

More human-memorable of safety/liveness: Safety - something bad will never
happen; Liveness - system should always make progress.

This type of reasoning/formal proofs is what allows us to make high level
statements such as ``live under synchrony, safe under async'' in PBFT, etc.

There's a lot more to this post, but that's a good start. Worth re-visiting.

\textbf{Vitalik - The Triangle of Harm (2017)}
\link{https://vitalik.ca/general/2017/07/16/triangle_of_harm.html}{link}

Goal: to understand roughly overview of incentive structure and constraints in
e.g. Casper.

Illustration: http://vitalik.ca/files/triangle_of_harm.png

Majority (M), minority (m), and protocol/users (p). Different attack vectors:

- M->m: majority griefing, 51% censorship
- m->M: minority griefing (e.g. feather forking)
- m->p: Minority attacks on protocol. e.g. Finney attacks
- M->p: 51% attacks

These are adverserial attacks.

What is a Finney attack?
In PoW, a miner mines a block with his tx and doesn't reveal it, instead double
spending with 0 or 1 confirmations.

What is feather forking?
A minority refuses to mine a block that contains undesired txs / attempts to
revert block.

What is a 51% censorship attack?
When cartel of miners refuse to accept blocks from minority.

What is a 51% attack?
When you control majority of hash power, you can double spend and release a
longer chain.

What's an example of a successful 51% attack?
Bitcoin Gold 2018 May. Even 20 confirmations wasn't safe. ~$18M.

Link: https://forum.bitcoingold.org/t/double-spend-attacks-on-exchanges/1362

The idea with Casper's design is to put an upper limit on the amount of
(economic) harm that can be caused to participants for all four classes of
attacks. This is the essence of trust minimization.

Bitcoin/PoW-based doesn't protect against Majority 51% types of attacks at all.

There is something quite profound here. The observation is made that, while
Nakamoto Consensus / PoW is punshing dissent (go with consensus, majority wins),
Casper punishes equivocation.

I.e. if you send two inconsistent messages, vs if you are with majority or
minority.

``The majority can attack the protocol only at heavy cost, and the majority
cannot cause the minority to lose money.''.

It is more difficult when it comes to liveness fault and censorship. Hm.

What is speaker/listener equivalence?
If B says they didn't receive message from A, can't tell the following scenarios
apart: (i) A didn't send message (ii) B pretended not to see it.

This leads to things like: punishing both sides (Game theoretic basis for this I
believe?) This leads to griefing and we can do something called *griefing factor
analysis* to be more rigorous about it.

What does it mean for a griefing factor to be 3 (and 0 and inf)?
If protocol allows me to cause you to lose $3 at cost of $1, griefing factor is
3. If I can't cause you to lose money, it's 0, and if it is free, it is
infinite.

When we have speaker/listener dichotomy, the griefing factor can't globally be
bounded above by a value above 1, for obvious reasons (if 0.5 then inverse is 2).

Sometimes can be useful to have griefing factor be 2:0.5, e.g. 2 for majority
attackers and 0.5 for minority, considering rarity.

Protocol utility function: how well doing, e.g. in PoW how much is on main chain
vs uncles. Asssuming we can formalize this wrt safety/liveness faults, this
leads to an optimization problem. Woop woop.

Worth re-reading. Taking notes a bit too close to reading so possibly didn't
stick as deep as it could've.

\textbf{COLONY Whitepaper (2018)}

\link{https://colony.io/whitepaper.pdf}{link}

Warning: System theoretical and not practical yet. Skimming to get some
inspiration for funding structure etc. Timebox.

It's a layer of human capital, a re-emergence of nature of the firm in
trust-minimized environments. On chain actions.

Colony is the structure. Tasks are subdivided into achievable units and then
created, assigned, completed. Tasks can then be put into various domains to
group them.

Funding Allocation/Proposal described in section 8. There's a Reputation system
in section 6.

Reputation decays automatically and can't be transferred. Reputation Mining
happens outside of chain. There is a Dispute Resolution System. And a Reward
Payout Process.

Some distinction between profit/no-profit/voluntary? They use some numerical
parameters that aren't verified.

Have they undergone an audit? How good are their contracts?

There is a recovery mode as escape hatch for now to access funds.

Tasks are the smallest unit. They have a manager (defining/coordinating
delivery), worker (executer), and evaluator (completed satisfactory).

Where is the funder?

Manager selects evaluator and worker, and specifies rewards for all three, as
well as spec and due date. Small stake but mostly to discover spam.

Funding proposals separate?

Domains are like folders in a computer. Right. Objections are raised to level
above, so Development etc. I get the idea but is this anchored in reality? If
you have a swarm with designers and dev and so on, do you really want to raise
objections to global design function? Almost all orgs re-invent cross-matrix
(Grove), so why this hierarchy? They do say it is meant to be used ad hoc
though, so no big deal.

At chapter 4, skipping to read briefly reputation 6 and funding 8.

Reputation is tightly coupled to domain. So I can have a backend reputation and
a frontend reputation. Seems like there's a risk to lead to segregation and
politics.

You earn reputation by completing tasks as well as dispute resolution a bit.

Why use reputation for punishing uncomplete tasks as opposed to money stake?
Maybe good, maybe bad.

Three cases: no task minus, ok task plus great task plus 1.5

Skipping reputation calculation 7 (wow big one).

Funds and Bounties. Each domain and task has an associated pot.

All tokens and currencies are in the main contract? Seems brittle. Maybe I
misunderstood. I'd rather see this be p2p at its core though.

Anyone part of colony can create proposal, req 0.1% of domain reputation. That's
nice. Funding queue. Interesting.

More reputation backs funding proposal the more backing/funding. That's another
nice idea.

Concrete example of possible over engineering: They add this ``priority funding'' mechanism and
say ``imagine this will be useful'' - so it doesn't come from a specific
experienced problem.

Conclusion: It has some interesting ideas, but in general it seems like a whole
lot of ``stuff'' that's just in there. What's the minimal core? More precisely:
1. Are they using it themselves 100%? What's the experience?
2. Is anyone out there using it yet?

I'd like to see some evidence of above first.

Further reads: DAICO, Truebit, etc
Meta mistake: Reading and alttab as opposed to closing book and reading for 10m, better for synthesis.

\textbf{Augur: a Decentralized Oracle and Prediction Market Platform (2018)}

\link{https://github.com/AugurProject/whitepaper/blob/master/english/whitepaper.pdf}{link}

State: live on mainnet! Prediction markets have been around a while as well.
Project quite old in Ethereum, 2014.

Reading/skimming to understand if there's some mention on comparison with
forecasting and bounties etc. See
https://discuss.status.im/t/sitg-experiment-1-status-intense-micro-adoption/401/4
thread

Problem statement: I want to fund a certain outcome so I stake $1000, someone
can be responsible for self-risk of $100. The idea being that that person tries
to get outcome done.

However, there's a side effect here. It seems functionally similiar to a
prediction market, since no PoW is needed. This shifts incentives - really what
I'm doing is not funding as muh as betting on outcome, on both sides. This would
lead the big bet to be incentivized to sabotage to get my side to win. Funding
is also almost by necessity not the same as betting, because you want a surplus.

Is predictions only about forecasting with observations or does it including
active intervention? To what degree?

Let's read with computer closed this time for a bit.

Nothing specific that is relevant right now in the whitepaper. Little on
applications. They talk about various states of bets - creation, trade,
reporting and settlement.

Also mention REP and its use, not needed for trade but for creation etc. Open
market where you buy shares, like 0.7 on outcome A or 0.3 on outcome B.
Decentralized oracle reporting, e.g. some URL etc, is used and reporting is
profit-based. Also dispute mechanisms and possible forking of universes. Fee
windows. Market event as source of truth basded on some oracle.

If you forecast incorrectly you lose money, but this lingo doesn't jive with
funding at all. Why? Is it like the definition of truth, that it has to be well
founded (eqv here being proof of work/plan of action?)

Oracle / resolution source: connect real world to blockchain. Incentivized to
tell the truth.

Connection with mechanism design: in prediction markets we want people to be
incentivized to report truth truthfully. This is an ``incentive compatible''
design. Worth re-reading mechanism design lit a bit more.

Practice research: launched quite recently, ~1000 markets and $1-2M staked.
Could it be used for OKRs perhaps? What benefits would it have?

Also checking: https://medium.com/coinmonks/why-is-no-one-really-using-augur-161448a8e198 re usability, though seems overcomeable.

Does it work through Status? Asking.

Other related directions:
1. History of prediction markets more generally?
2. Oracles. Szabo probably wrote something here. Cornell/IC3 had some interesting service as well. Town Crier.

One key question that would be useful to answer is: To what extent is what you
are considering re SITG funding different from what they already have? Right now
my hunch is partially language, but also (a) precommitment, not liquid (b) tied
to specific piece of work (credible) / locus of control.

\textbf{Scuttlebutt handbook (?)}
\link{https://www.scuttlebutt.nz/}{link}

Decentralized chat. Reading to understand how it works differently, pull vs
push, offline, gossip, etc. Used soemwhat. Not part of Ethereum ecosystem.

There's a Gossip protocol and you subscribe to people and pubs to learn more.

They have different apps, which are different ways of interacting with your
scuttlebutt. Magic glasses. (This is getting pretty far from cryptoeconomics but
whatever).

- How does it do that more precisely? I.e. different rendering, markdown/html, etc.
- If you don't like something block. How does it deal with negative reputation / spam, if at all?

E.g. git ssb, completely different. How does that work?

Design goal: avoid centralization and singletons. This means all peers are same.
They still use pubs, which helps with offline inboxing. Some mention of NAT and
so on, an area I'm not too familiar with.

But no special data or access on a pub, instead you can have multiple. So
different from email server. This is design we should have for offline inboxing.

``Change pubs without losing data or identity''.

Interesting point - it avoids singletons, e.g. things like a DHT and a global
blockchain.

FB etc is also p2p in some sense, but centralized implementation. Then real
human p2p you have network p2p on top of it, at network layer.

They claim blockchains are heavy (storage, cpu) and DHT prone to spam. Hmmmm,
interesting point. So how does it work?

Design Challenge: Sybil Attacks.

How email deals with spam: filter it out with pattern matching.
How social networks deal with spam: solicited, ie only receive from follows/friends.

in SecureScuttleButt (SSB) you only communicate with trusted peers (friends). It's a social system.

Open gossip protocol: everyone has a journal with write-only, when you see a
friend you make a copy, to send message you encrypt with their key in your
diary, when you read friend and can decrypt message it is for you.

Wait, when you are on dsame wifi as a friends computers will gossip, so don't
need to be on the internet to do it? That's extremely powerful.

Genesis from Dominic Tarr and Snob. Inspired by Dynamo paper, CRDTs, Git, CouchDB.

In CouchDB you can tail -f DB and sync changes.

Using Trust in Open Networks - Trust ranking of shared data structures. Big
section with juicy stuff.

Two ways of dealing with trust - policy based and reputation based. Social
following is base layer trust.

Policy requires making decisions about other agents in the network, apparently.
Instead, reputation based trust built on top of user's decision, etc. Hm hm.

Example: search engines. PageRank; EigenTrust for p2p; propagation models;
Advogato; TrustMail etc. This is a big one.

Eigentrust algorithm for reputation Management in p2p networks seems relevant.
IIRC we looked into this a bit, worth revisiting.

Summary of a bunch of papers. 

Using Trust in Open Networks - this is a big topic worth revisiting.

Against consnesus. SSB wants to support pluralism and heterogeneity.

Locke philosophy on social contract. Just enough consensus to operate.
Accordibng to Locke, main feature of social contract is property rights.
Interestingtly, for SBB it might be message schemas (one person). Diff from
crypto?

What's the con of DHTs? ``peers collab anon'', ``cant estimate
trusthworthiness'' => poor privacy (can add peers to monitor you); poor sybil
resistance (no way of knowing peer near you is on your side). For SSB, mapping
computer network along social network (less spam, no friend with spam). This is
a really interesting point.

True Name is ed25519 key pair (libsodium). Nick Name (petname) for other peer.
Human memorably symlink. Diff from property per se.

Aside on boat vs different boats. Plato example ``philosopher king''. Captain of
a ship, all in the same boat. But different between boats. Hmm. Ship of a state?
Scale argument, interesting mental image considering risk of one boat vs
multiple not same profile (lit - ``in the same boat'').

Message - interpretation is subjective and Patchwork is just one of them. They
are subjective. Meaning when two peers have same interpreation.

Message: sig, sig pub key, content hash prev msg, seq num, timestamp, id of hash
algo (sha256), content object.

Example content object: {type: vote, vote {link: ...., value 1}}

Unclear what metadata privacy looks like.

Gossip: People relay/gossip info, improving availability. Messages signed so
can't be forged, i.e. secure gossip.

Users choose which feeds to sync by following. It looks at contact messages to
know which users are followed.

Replication: req newer than the one you know about, simple. Table of known
peers, cycle through. Since messages are signed they can be distributed throguh
sneakernet, or pigeon post. Which is awesome.

Transitiive connections between Alice and Dan, via Pub etc.

Blocking, can block individual. But not cryptoeconomically secure I believe, no
moderation tools. Trust social scalability? Unclear. Subscribe to other peoples
moderation? Humhum. Contact spam?

Pubs run at public IPs, follow users. Mail bots improve uptime and availability.
Anynody can create and intro own. Where is guide for how to run it?

Oh they have react nativ nodes and all kinds of stuff. Hm hm.

Try Patchwork.

How does public channels work? And private channels?

DHT vs Gossip dichotomy, think more.

Scuttlebutt, run via WS possible. We should be able to do this.

Subscribing to a channel lets you read messages from friends and friends of
friends. But not from folks not in network :o It is just a way to org messges
and conversation.

Interesting stuff, worth revisiting and trying out.

\textbf{Scuttlebutt Protocol Guide (-)}

\link{https://ssbc.github.io/scuttlebutt-protocol-guide/}{link}

Idenity keypair. Discovery in 3 ways local, invite, pub. Need ip, port and
pubkey for peer. Local UDP broadcast every second availability.

Invite includes domain and secret code user can redeem so pub can follow back.

Pub advertised on someone's feed.

Using a secret handshake key exchange, 4 step handshake. TCP, hello-hello-auth-accept.

How can MITM not learn pub key from either peer?

Compute ephemeral keys for FS. Probably worth re-reading Double Ratchet etc spec.

There's box stream and RPC protocol. This isn't meant for skimming.

createHistoryStream, ask peers if they have relevant messages. Signal which
blobs want and have.

Feeds and follow graph - 1 hop - explicitly follow; 2 hop - see in feed, friends
of friends; 3 hop - fetched but not visibile; 4 hop - not fetched.

Pubs stable IP, allow direct TCP. Gathering point for people. Follow and follow back.

Encrypting and decrypting procedure outline.

Darkness big questionmark.

Also consider writing full sentences and paragrahs.

\textbf{Reading lists}
Distributed systems, solid: https://pdos.csail.mit.edu/6.824/schedule.html


Questions:
- What's a good primer to byzantine fault tolerance consensus?
- What classes of problems do you actually need consensus for? Not clear it is always needed.

https://ethresear.ch/t/explanation-of-daicos/465

https://blog.ethereum.org/2015/06/06/the-problem-of-censorship/

Truebit paper - verification game: https://people.cs.uchicago.edu/~teutsch/papers/truebit.pdf

Nature of the firm 1937: http://www3.nccu.edu.tw/~jsfeng/CPEC11.pdf

Initial ERC20/ICO definition?

Assurance contracts and lucid free rider problem explanation, etc

Game theory refresh/basics, some good examples in presentation from way back

Hayek - The Use of Knowledge in Society (1945) https://www.kysq.org/docs/Hayek_45.pdf

Hardin 1968 - Tragedy of the Commons
Ostrom 1990 - Governing the Commons

SSB Handbook - dist sys see model

Town Crier - authenticated data feed http://www.initc3.org/files/tc.pdf

Schelling, Thomas C. (1966). Arms and Influence - talks about precommitment supposedly, weakness=strength

Locke social contract

Read more about Gossip protocol
Also reputation systems (see SSB ex)

Sybil attack

Double Ratchet X3DH HMAC PFS

https://tools.ietf.org/html/rfc2104


\end{document}
