\documentclass[12pt]{report}
\overfullrule=2cm

\usepackage{hyperref}

\newcommand{\link}[2]{\href{#1}{#2}}

\begin{document}

\title{Notes on cryptoeconomics}
\author{Oskar Thoren\thanks{Email: ot@oskarthoren.com}$^{,}$\thanks{Web: http://oskarth.com}}

\maketitle

\chapter{Prelude}

Notes on cryptoeconomics and related subjects. Started September 9, 2018.

With a focus towards specific problems that I want to solve. These problems
should have more precise problem statement. A rough outline will do for now.
These are specific problems that are meaningful and relevant and guide reading,
even if more general tools are desirable and there is other problems and stuff
that is useful.

Additionally, specific papers and free recall notes of these. Then we'll see
where a synthesis makes sense.

Also roughly answer things like: what do you know and what would be useful to
know?

Previously did a write-up of A Layman's Introduction to Cryptoeconomics.

\textbf{Questions}:

1) Incentivized Whisper nodes, including mail server. General problem: full node
incentivization and running without a cluster or servers at all.

See things like: Miners; rent proposal; full node incentivization, as well as
altruistic models (scale arguments, E.O. Wilson tangent?). Also worth checking
re BT and Tor nodes, etc. Any form of p2p.

Litmus test: A system survive without a cluster or subsidised servers.

2) DAO and compensation, funding of public goods and the likes.

Should probable be phrased as question. Finding a good question statement is
useful. See Polya for examples of ways of thinking structurally about these
problems.

Litmus test: organization/community survive without core contributors/paycheck.

3) More generally, how to balance decentralization/scalability/security? This is
essentially Ethereum 2.0 and grokking it at a fundamental level.

\chapter{Readings}

Anything by Vitalik or Szabo is a good start and meaty. Have a bunch in inbox.
Meta: what specific ways of reading is useful? Something like the following to
keep in mind:

- Who are the actors in this system?
- What's the set of rewards and punishments?
- What tools are used and introduced?
- Is there any empirical basis for this or is it still a theoretical construct?
- Lindy effect: Comparable that's 30y/10y or so old? Otherwise maybe BS.

\section{Vitalik - Minimal Slashing Conditions (2017)}
\link{https://medium.com/@VitalikButerin/minimal-slashing-conditions-20f0b500fc6c}{link}

Interest of this is around learning how to think about *slashing conditions*,
i.e. punishing bad behavior. Probably lacking some pre-requsites in *byzantine
fault tolerance consensus algorithms*.

What is the intention of using "economic finality" in Casper?
To make 51% attacks very expensive (~$70m) once block is finalized. Even if
majority of validators work together it means huge economic cost.

What does it mean for a block to be economically finalized?
\textbf{Definition}: a block is *economically finalized* with *cryptoeconomic
security margin* $X if it is guaranteed to be in the canonical chain for ever,
or if it costs set of actors at least $X to remove it from the state.

This is key to Casper design. Validators must submit a *security deposit* to
participate, and this can get taken away if the protocol isn't followed. Under
what conditions is what is referred to as *slashing conditions*.

Example: PREPARE and COMMIT statements. Key to byzantine fault tolerance
consensus two phase consensus design apparently, but not elaborated on right
now.

If a validator sends two PREPARE messages within same epoch but with different
hashes, say, that should be punished. It's easy for an honest validator not to
do this.

When is a block hash *finalized*?
When, within a given epoch, you get enough messages of type `[COMMIT, epoch,
  hash]` that the validator's deposits add up to 2/3 of the *active validator
set* deposits.

There are some conditions that slashing conditinos have to meet. One is around
*accountable safety*, which says something like: if two hashes gets committed (fork) then
at least 1/3 of validators can be penalized. Other is around *plausible liveness*, which
is something like: system shouldn't be stuck, there has to be a set of messages
that can be sent that 2/3 agree on without validating slashing conditions.

Let's be a bit more formal.

What conditions does *slashing conditions* need to satisfy? (sloppy)
Accountable safety and plausible liveness.

What does Vitalik mean by *accountable safety*?
If two conflicting hashes gets finalized, it must be (provably) true that at
least 1/3 of validators violated some slashing conditions. This is the
``economic finality'' idea.

What does Vitalik mean by *plausible liveness*?
Unless 1/3 of validators violate some slashing condition, there must be a set of
messages 2/3 of validators can send that finalize a new hash without violating
slashing conditions.

This reminds me of: Schelling points, as well as structured order for Anki (Q/A).

I assume this is directly taken from BFT literature regarding safety and
liveness. It'd be useful to understand these in more depth, along with things
like sync assumptions (sync/partial/async). It isn't clear to me how this is
directly related to any of the specific problems addressed in top, though it is
vital for Ethereum 2.0 in general.

There's examples of safety but not liveness, and v.v. Shows failure modes.

These are like little puzzles. Should be able to come up with answers myself.

Quoting algorithm 1:
> Algorithm 1: every validator has exactly one opportunity to send a message of
the form ["COMMIT", HASH]. If 2/3 of validators send a COMMIT for the same hash,
that hash is finalized. Sending two COMMIT messages violates a slashing
condition.

Is this safe and live? Safety: if we have two conflicting hashes...

Quoting algorithm 2:
> Algorithm 2: every validator has exactly one opportunity to send a message of
the form ["COMMIT", HASH, epoch]. If 2/3 of validators send a COMMIT for the
same hash with the same epoch number, that hash is finalized. Sending two COMMIT
messages with different hashes with the same epoch number violates a slashing
condition.

Is this safe and live?

Not enough time to do this properly. Worth re-visiting though.

The pudding is: you can get safety and liveness, but this is actually quite
hard. It requires four slashing conditions, and there's a formal proof by Yoichi
here: https://yoichihirai.com/minimal.pdf

These are, roughly: COMMIT REQ (sending commit requires 2/3 prepares), PREPARE
REQ (don't quite follow, but ancestor epoch related), PREPARE COMMIT CONSISTENCY
(if you make commit you saw prepares, so prepares should ref recent epoch), NO
DBL PREPARE (can't prepare twice in one epoch).

I'm curious where this split in PREPARE and COMMIT comes from, surely that's a
canonical BFT paper somewhere? Same re safety and liveness. What does distsys
MIT curriculum say? (can't find anything at first glance).

More human-memorable of safety/liveness: Safety - something bad will never
happen; Liveness - system should always make progress.

This type of reasoning/formal proofs is what allows us to make high level
statements such as ``live under synchrony, safe under async'' in PBFT, etc.

There's a lot more to this post, but that's a good start. Worth re-visiting.

\textbf{Vitalik - The Triangle of Harm (2017)}
\link{https://vitalik.ca/general/2017/07/16/triangle_of_harm.html}{link}

Goal: to understand roughly overview of incentive structure and constraints in
e.g. Casper.

Illustration: http://vitalik.ca/files/triangle_of_harm.png

Majority (M), minority (m), and protocol/users (p). Different attack vectors:

- M->m: majority griefing, 51% censorship
- m->M: minority griefing (e.g. feather forking)
- m->p: Minority attacks on protocol. e.g. Finney attacks
- M->p: 51% attacks

These are adverserial attacks.

What is a Finney attack?
In PoW, a miner mines a block with his tx and doesn't reveal it, instead double
spending with 0 or 1 confirmations.

What is feather forking?
A minority refuses to mine a block that contains undesired txs / attempts to
revert block.

What is a 51% censorship attack?
When cartel of miners refuse to accept blocks from minority.

What is a 51% attack?
When you control majority of hash power, you can double spend and release a
longer chain.

What's an example of a successful 51% attack?
Bitcoin Gold 2018 May. Even 20 confirmations wasn't safe. ~$18M.

Link: https://forum.bitcoingold.org/t/double-spend-attacks-on-exchanges/1362

The idea with Casper's design is to put an upper limit on the amount of
(economic) harm that can be caused to participants for all four classes of
attacks. This is the essence of trust minimization.

Bitcoin/PoW-based doesn't protect against Majority 51% types of attacks at all.

There is something quite profound here. The observation is made that, while
Nakamoto Consensus / PoW is punshing dissent (go with consensus, majority wins),
Casper punishes equivocation.

I.e. if you send two inconsistent messages, vs if you are with majority or
minority.

``The majority can attack the protocol only at heavy cost, and the majority
cannot cause the minority to lose money.''.

It is more difficult when it comes to liveness fault and censorship. Hm.

What is speaker/listener equivalence?
If B says they didn't receive message from A, can't tell the following scenarios
apart: (i) A didn't send message (ii) B pretended not to see it.

This leads to things like: punishing both sides (Game theoretic basis for this I
believe?) This leads to griefing and we can do something called *griefing factor
analysis* to be more rigorous about it.

What does it mean for a griefing factor to be 3 (and 0 and inf)?
If protocol allows me to cause you to lose $3 at cost of $1, griefing factor is
3. If I can't cause you to lose money, it's 0, and if it is free, it is
infinite.

When we have speaker/listener dichotomy, the griefing factor can't globally be
bounded above by a value above 1, for obvious reasons (if 0.5 then inverse is 2).

Sometimes can be useful to have griefing factor be 2:0.5, e.g. 2 for majority
attackers and 0.5 for minority, considering rarity.

Protocol utility function: how well doing, e.g. in PoW how much is on main chain
vs uncles. Asssuming we can formalize this wrt safety/liveness faults, this
leads to an optimization problem. Woop woop.

Worth re-reading. Taking notes a bit too close to reading so possibly didn't
stick as deep as it could've.


\textbf{Reading lists}
Distributed systems, solid: https://pdos.csail.mit.edu/6.824/schedule.html


Questions:
- What's a good primer to byzantine fault tolerance consensus?
- What classes of problems do you actually need consensus for? Not clear it is always needed.


https://blog.ethereum.org/2015/06/06/the-problem-of-censorship/

\end{document}
