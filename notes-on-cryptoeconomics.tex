\documentclass[12pt]{report}
\overfullrule=2cm

\usepackage{hyperref}

\newcommand{\link}[2]{\href{#1}{#2}}

\begin{document}

\title{Notes on cryptoeconomics}
\author{Oskar Thoren\thanks{Email: ot@oskarthoren.com}$^{,}$\thanks{Web: http://oskarth.com}}

\maketitle

\chapter{Prelude}

Notes on cryptoeconomics and related subjects. Started September 9, 2018.

With a focus towards specific problems that I want to solve. These problems
should have more precise problem statement. A rough outline will do for now.
These are specific problems that are meaningful and relevant and guide reading,
even if more general tools are desirable and there is other problems and stuff
that is useful.

Additionally, specific papers and free recall notes of these. Then we'll see
where a synthesis makes sense.

Also roughly answer things like: what do you know and what would be useful to
know?

Previously did a write-up of A Layman's Introduction to Cryptoeconomics.

\textbf{Questions}:

1) Incentivized Whisper nodes, including mail server. General problem: full node
incentivization and running without a cluster or servers at all.

See things like: Miners; rent proposal; full node incentivization, as well as
altruistic models (scale arguments, E.O. Wilson tangent?). Also worth checking
re BT and Tor nodes, etc. Any form of p2p.

Litmus test: A system survive without a cluster or subsidised servers.

2) DAO and compensation, funding of public goods and the likes.

Should probable be phrased as question. Finding a good question statement is
useful. See Polya for examples of ways of thinking structurally about these
problems.

Litmus test: organization/community survive without core contributors/paycheck.

3) More generally, how to balance decentralization/scalability/security? This is
essentially Ethereum 2.0 and grokking it at a fundamental level.

\chapter{Readings}

Anything by Vitalik or Szabo is a good start and meaty. Have a bunch in inbox.
Meta: what specific ways of reading is useful? Something like the following to
keep in mind:

- Who are the actors in this system?
- What's the set of rewards and punishments?
- What tools are used and introduced?
- Is there any empirical basis for this or is it still a theoretical construct?
- Lindy effect: Comparable that's 30y/10y or so old? Otherwise maybe BS.

\section{Vitalik - Minimal Slashing Conditions (2017)}
\link{https://medium.com/@VitalikButerin/minimal-slashing-conditions-20f0b500fc6c}{link}

Interest of this is around learning how to think about *slashing conditions*,
i.e. punishing bad behavior. Probably lacking some pre-requsites in *byzantine
fault tolerance consensus algorithms*.

What is the intention of using "economic finality" in Casper?
To make 51% attacks very expensive (~$70m) once block is finalized. Even if
majority of validators work together it means huge economic cost.

What does it mean for a block to be economically finalized?
\textbf{Definition}: a block is *economically finalized* with *cryptoeconomic
security margin* $X if it is guaranteed to be in the canonical chain for ever,
or if it costs set of actors at least $X to remove it from the state.

This is key to Casper design. Validators must submit a *security deposit* to
participate, and this can get taken away if the protocol isn't followed. Under
what conditions is what is referred to as *slashing conditions*.

Example: PREPARE and COMMIT statements. Key to byzantine fault tolerance
consensus two phase consensus design apparently, but not elaborated on right
now.

If a validator sends two PREPARE messages within same epoch but with different
hashes, say, that should be punished. It's easy for an honest validator not to
do this.

When is a block hash *finalized*?
When, within a given epoch, you get enough messages of type `[COMMIT, epoch,
  hash]` that the validator's deposits add up to 2/3 of the *active validator
set* deposits.

There are some conditions that slashing conditinos have to meet. One is around
*accountable safety*, which says something like: if two hashes gets committed (fork) then
at least 1/3 of validators can be penalized. Other is around *plausible liveness*, which
is something like: system shouldn't be stuck, there has to be a set of messages
that can be sent that 2/3 agree on without validating slashing conditions.

Let's be a bit more formal.

What conditions does *slashing conditions* need to satisfy? (sloppy)
Accountable safety and plausible liveness.

What does Vitalik mean by *accountable safety*?
If two conflicting hashes gets finalized, it must be (provably) true that at
least 1/3 of validators violated some slashing conditions. This is the
``economic finality'' idea.

What does Vitalik mean by *plausible liveness*?
Unless 1/3 of validators violate some slashing condition, there must be a set of
messages 2/3 of validators can send that finalize a new hash without violating
slashing conditions.

This reminds me of: Schelling points, as well as structured order for Anki (Q/A).

I assume this is directly taken from BFT literature regarding safety and
liveness. It'd be useful to understand these in more depth, along with things
like sync assumptions (sync/partial/async). It isn't clear to me how this is
directly related to any of the specific problems addressed in top, though it is
vital for Ethereum 2.0 in general.

There's examples of safety but not liveness, and v.v. Shows failure modes.

These are like little puzzles. Should be able to come up with answers myself.

Quoting algorithm 1:
> Algorithm 1: every validator has exactly one opportunity to send a message of
the form ["COMMIT", HASH]. If 2/3 of validators send a COMMIT for the same hash,
that hash is finalized. Sending two COMMIT messages violates a slashing
condition.

Is this safe and live? Safety: if we have two conflicting hashes...

Quoting algorithm 2:
> Algorithm 2: every validator has exactly one opportunity to send a message of
the form ["COMMIT", HASH, epoch]. If 2/3 of validators send a COMMIT for the
same hash with the same epoch number, that hash is finalized. Sending two COMMIT
messages with different hashes with the same epoch number violates a slashing
condition.

Is this safe and live?

Not enough time to do this properly. Worth re-visiting though.

The pudding is: you can get safety and liveness, but this is actually quite
hard. It requires four slashing conditions, and there's a formal proof by Yoichi
here: https://yoichihirai.com/minimal.pdf

These are, roughly: COMMIT REQ (sending commit requires 2/3 prepares), PREPARE
REQ (don't quite follow, but ancestor epoch related), PREPARE COMMIT CONSISTENCY
(if you make commit you saw prepares, so prepares should ref recent epoch), NO
DBL PREPARE (can't prepare twice in one epoch).

I'm curious where this split in PREPARE and COMMIT comes from, surely that's a
canonical BFT paper somewhere? Same re safety and liveness. What does distsys
MIT curriculum say? (can't find anything at first glance).

More human-memorable of safety/liveness: Safety - something bad will never
happen; Liveness - system should always make progress.

This type of reasoning/formal proofs is what allows us to make high level
statements such as ``live under synchrony, safe under async'' in PBFT, etc.

There's a lot more to this post, but that's a good start. Worth re-visiting.

\textbf{Vitalik - The Triangle of Harm (2017)}
\link{https://vitalik.ca/general/2017/07/16/triangle_of_harm.html}{link}

Goal: to understand roughly overview of incentive structure and constraints in
e.g. Casper.

Illustration: http://vitalik.ca/files/triangle_of_harm.png

Majority (M), minority (m), and protocol/users (p). Different attack vectors:

- M->m: majority griefing, 51% censorship
- m->M: minority griefing (e.g. feather forking)
- m->p: Minority attacks on protocol. e.g. Finney attacks
- M->p: 51% attacks

These are adverserial attacks.

What is a Finney attack?
In PoW, a miner mines a block with his tx and doesn't reveal it, instead double
spending with 0 or 1 confirmations.

What is feather forking?
A minority refuses to mine a block that contains undesired txs / attempts to
revert block.

What is a 51% censorship attack?
When cartel of miners refuse to accept blocks from minority.

What is a 51% attack?
When you control majority of hash power, you can double spend and release a
longer chain.

What's an example of a successful 51% attack?
Bitcoin Gold 2018 May. Even 20 confirmations wasn't safe. ~$18M.

Link: https://forum.bitcoingold.org/t/double-spend-attacks-on-exchanges/1362

The idea with Casper's design is to put an upper limit on the amount of
(economic) harm that can be caused to participants for all four classes of
attacks. This is the essence of trust minimization.

Bitcoin/PoW-based doesn't protect against Majority 51% types of attacks at all.

There is something quite profound here. The observation is made that, while
Nakamoto Consensus / PoW is punshing dissent (go with consensus, majority wins),
Casper punishes equivocation.

I.e. if you send two inconsistent messages, vs if you are with majority or
minority.

``The majority can attack the protocol only at heavy cost, and the majority
cannot cause the minority to lose money.''.

It is more difficult when it comes to liveness fault and censorship. Hm.

What is speaker/listener equivalence?
If B says they didn't receive message from A, can't tell the following scenarios
apart: (i) A didn't send message (ii) B pretended not to see it.

This leads to things like: punishing both sides (Game theoretic basis for this I
believe?) This leads to griefing and we can do something called *griefing factor
analysis* to be more rigorous about it.

What does it mean for a griefing factor to be 3 (and 0 and inf)?
If protocol allows me to cause you to lose $3 at cost of $1, griefing factor is
3. If I can't cause you to lose money, it's 0, and if it is free, it is
infinite.

When we have speaker/listener dichotomy, the griefing factor can't globally be
bounded above by a value above 1, for obvious reasons (if 0.5 then inverse is 2).

Sometimes can be useful to have griefing factor be 2:0.5, e.g. 2 for majority
attackers and 0.5 for minority, considering rarity.

Protocol utility function: how well doing, e.g. in PoW how much is on main chain
vs uncles. Asssuming we can formalize this wrt safety/liveness faults, this
leads to an optimization problem. Woop woop.

Worth re-reading. Taking notes a bit too close to reading so possibly didn't
stick as deep as it could've.

\textbf{COLONY Whitepaper (2018)}

\link{https://colony.io/whitepaper.pdf}{link}

Warning: System theoretical and not practical yet. Skimming to get some
inspiration for funding structure etc. Timebox.

It's a layer of human capital, a re-emergence of nature of the firm in
trust-minimized environments. On chain actions.

Colony is the structure. Tasks are subdivided into achievable units and then
created, assigned, completed. Tasks can then be put into various domains to
group them.

Funding Allocation/Proposal described in section 8. There's a Reputation system
in section 6.

Reputation decays automatically and can't be transferred. Reputation Mining
happens outside of chain. There is a Dispute Resolution System. And a Reward
Payout Process.

Some distinction between profit/no-profit/voluntary? They use some numerical
parameters that aren't verified.

Have they undergone an audit? How good are their contracts?

There is a recovery mode as escape hatch for now to access funds.

Tasks are the smallest unit. They have a manager (defining/coordinating
delivery), worker (executer), and evaluator (completed satisfactory).

Where is the funder?

Manager selects evaluator and worker, and specifies rewards for all three, as
well as spec and due date. Small stake but mostly to discover spam.

Funding proposals separate?

Domains are like folders in a computer. Right. Objections are raised to level
above, so Development etc. I get the idea but is this anchored in reality? If
you have a swarm with designers and dev and so on, do you really want to raise
objections to global design function? Almost all orgs re-invent cross-matrix
(Grove), so why this hierarchy? They do say it is meant to be used ad hoc
though, so no big deal.

At chapter 4, skipping to read briefly reputation 6 and funding 8.

Reputation is tightly coupled to domain. So I can have a backend reputation and
a frontend reputation. Seems like there's a risk to lead to segregation and
politics.

You earn reputation by completing tasks as well as dispute resolution a bit.

Why use reputation for punishing uncomplete tasks as opposed to money stake?
Maybe good, maybe bad.

Three cases: no task minus, ok task plus great task plus 1.5

Skipping reputation calculation 7 (wow big one).

Funds and Bounties. Each domain and task has an associated pot.

All tokens and currencies are in the main contract? Seems brittle. Maybe I
misunderstood. I'd rather see this be p2p at its core though.

Anyone part of colony can create proposal, req 0.1% of domain reputation. That's
nice. Funding queue. Interesting.

More reputation backs funding proposal the more backing/funding. That's another
nice idea.

Concrete example of possible over engineering: They add this ``priority funding'' mechanism and
say ``imagine this will be useful'' - so it doesn't come from a specific
experienced problem.

Conclusion: It has some interesting ideas, but in general it seems like a whole
lot of ``stuff'' that's just in there. What's the minimal core? More precisely:
1. Are they using it themselves 100%? What's the experience?
2. Is anyone out there using it yet?

I'd like to see some evidence of above first.

Further reads: DAICO, Truebit, etc
Meta mistake: Reading and alttab as opposed to closing book and reading for 10m, better for synthesis.

\textbf{Augur: a Decentralized Oracle and Prediction Market Platform (2018)}

\link{https://github.com/AugurProject/whitepaper/blob/master/english/whitepaper.pdf}{link}

State: live on mainnet! Prediction markets have been around a while as well.
Project quite old in Ethereum, 2014.

Reading/skimming to understand if there's some mention on comparison with
forecasting and bounties etc. See
https://discuss.status.im/t/sitg-experiment-1-status-intense-micro-adoption/401/4
thread

Problem statement: I want to fund a certain outcome so I stake $1000, someone
can be responsible for self-risk of $100. The idea being that that person tries
to get outcome done.

However, there's a side effect here. It seems functionally similiar to a
prediction market, since no PoW is needed. This shifts incentives - really what
I'm doing is not funding as muh as betting on outcome, on both sides. This would
lead the big bet to be incentivized to sabotage to get my side to win. Funding
is also almost by necessity not the same as betting, because you want a surplus.

Is predictions only about forecasting with observations or does it including
active intervention? To what degree?

Let's read with computer closed this time for a bit.

Nothing specific that is relevant right now in the whitepaper. Little on
applications. They talk about various states of bets - creation, trade,
reporting and settlement.

Also mention REP and its use, not needed for trade but for creation etc. Open
market where you buy shares, like 0.7 on outcome A or 0.3 on outcome B.
Decentralized oracle reporting, e.g. some URL etc, is used and reporting is
profit-based. Also dispute mechanisms and possible forking of universes. Fee
windows. Market event as source of truth basded on some oracle.

If you forecast incorrectly you lose money, but this lingo doesn't jive with
funding at all. Why? Is it like the definition of truth, that it has to be well
founded (eqv here being proof of work/plan of action?)

Oracle / resolution source: connect real world to blockchain. Incentivized to
tell the truth.

Connection with mechanism design: in prediction markets we want people to be
incentivized to report truth truthfully. This is an ``incentive compatible''
design. Worth re-reading mechanism design lit a bit more.

Practice research: launched quite recently, ~1000 markets and $1-2M staked.
Could it be used for OKRs perhaps? What benefits would it have?

Also checking: https://medium.com/coinmonks/why-is-no-one-really-using-augur-161448a8e198 re usability, though seems overcomeable.

Does it work through Status? Asking.

Other related directions:
1. History of prediction markets more generally?
2. Oracles. Szabo probably wrote something here. Cornell/IC3 had some interesting service as well. Town Crier.


\textbf{Reading lists}
Distributed systems, solid: https://pdos.csail.mit.edu/6.824/schedule.html


Questions:
- What's a good primer to byzantine fault tolerance consensus?
- What classes of problems do you actually need consensus for? Not clear it is always needed.

https://ethresear.ch/t/explanation-of-daicos/465

https://blog.ethereum.org/2015/06/06/the-problem-of-censorship/

Truebit paper - verification game: https://people.cs.uchicago.edu/~teutsch/papers/truebit.pdf

Nature of the firm 1937: http://www3.nccu.edu.tw/~jsfeng/CPEC11.pdf

Initial ERC20/ICO definition?

Assurance contracts and lucid free rider problem explanation, etc

Game theory refresh/basics, some good examples in presentation from way back

Hayek - The Use of Knowledge in Society (1945) https://www.kysq.org/docs/Hayek_45.pdf

Hardin 1968 - Tragedy of the Commons
Ostrom 1990 - Governing the Commons

SSB Handbook - dist sys see model

Town Crier - authenticated data feed http://www.initc3.org/files/tc.pdf


\end{document}
